{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to extract data from ravelry.com using API\n",
    "\n",
    "API documentation: https://www.ravelry.com/api\n",
    "\n",
    "Used read-only credentials for data retrieval.\n",
    "\n",
    "Get data for patterns sorted by most projects, yarns sorted by most projects, and shops in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials stored in text files\n",
    "\n",
    "username = open('../data/rav_user.txt').read()\n",
    "password = open('../data/rav_pass.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern listing results sorted by number of projects descending.\n",
    "# manually tested to see where the number of projects declines - very long tail!\n",
    "\n",
    "def get_pattern_info(query, username, password):\n",
    "    print(query)\n",
    "    print(username)\n",
    "    print(password)\n",
    "    print('https://api.ravelry.com/patterns/search.json')\n",
    "    res = requests.get('https://api.ravelry.com/patterns/search.json?query={}&sort=projects&page_size=1000&page=80'.format(query),\n",
    "                       auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_pattern_info('', username, password)\n",
    "result = json.loads(res.content)\n",
    "result['patterns']\n",
    "patterns_df = pd.DataFrame(result['patterns'])\n",
    "patterns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thoughts after looking at chunks of pattern listings\n",
    "\n",
    "Initially I was thinking to get top 10,000 but that might not make sense considering the long tail (see notes). Cutting off at patterns with at least 100 projects makes sense. 100 projects is enough to ensure that the pattern appeals to a good number of people (at least enough to create a project page for it). My purpose for this part of the analysis is to determine what type of patterns people like and what common characteristics there are - yarn weights, category, possibly amount of yarn required.\n",
    "\n",
    "notes:\n",
    "\n",
    "10,000th pattern has 241 projects, while 1st pattern has 23.6k.\n",
    "\n",
    "12,000th pattern has 206 projects. 15,000th project has 169. I'm actually a little surprised by the length of the tail.\n",
    "\n",
    "20,000th pattern has 130 projects. 30,000th has 88. 40,000th has 67. 60,000th has 43. 80,000th has 31."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan:\n",
    "\n",
    "Define a function and use for loop to get pattern ids. Page size = 1000 as that doesn't take long to run. Put the id column into a list.\n",
    "\n",
    "Using list of pattern ids, use a function and for loop to retrieve pattern details using the appropriate API method. Ravelry does allow for multiple pattern ids to be put into the method to retrieve details so I won't have to call the API 30,000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pattern_info(username, password):\n",
    "    pattid_list = []\n",
    "    for page in range(1, 31):\n",
    "        print(page)\n",
    "        res = requests.get('https://api.ravelry.com/patterns/search.json?sort=projects&page_size=1000&page=' + str(page),\n",
    "                       auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        result = json.loads(res.content)\n",
    "        patterns_df = pd.DataFrame(result['patterns'])\n",
    "        print(patterns_df.shape)\n",
    "        pattid_list.append(patterns_df.id.tolist())\n",
    "    return pattid_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns pattern ids as integers, list of lists (a list for each page of results)\n",
    "\n",
    "pattid_list = get_pattern_info(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to flatten list, and change integers into strings\n",
    "\n",
    "pattid_flat_list = [str(patt_id) for sublist in pattid_list for patt_id in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimented with calling different numbers of pattern ids to see what the API would allow. 30,000 and even 1000 was too many as expected. (Getting 1000 for pattern listings was fine since that pulls much less information.) Settled on 200 as a reasonable number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('https://api.ravelry.com/patterns.json?ids=' + '+'.join(pattid_list_str[:200]), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan of attack\n",
    "\n",
    "1: write chunk of code to return pattern details for a single id. Should be made into a dataframe and pivoted so that information is in a row instead of a column. I was originally looking at melt or wide_to_long, but Mary suggested transpose - much better!\n",
    "\n",
    "2: expand the code to take multiple ids. After talking to M&M, wrote function and for loop to iterate through a test list of 10 ids pulled from the flattened/string-ified list. Continued to use transform to switch rows and columns, and appended each result to a dataframe. I could probably have skipped this step, but I wanted to test the code at this interval so I could fix potential problems without hitting the API for too much.\n",
    "\n",
    "3: chunk the list of pattern ids into groups of 200 to reduce calls on the API. The integers in the list have already been changed to strings so the ids can be joined with '+' as in the API documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: retrieving details for an individual pattern id.\n",
    "\n",
    "first = requests.get('https://api.ravelry.com/patterns.json?ids=' +\n",
    "                     str(211562), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "first_result = json.loads(first.content)\n",
    "first_detail_df = pd.DataFrame(first_result['patterns']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_detail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: retrieving details for several ids in a list.\n",
    "\n",
    "second_test_id_list = ['211562', '130787', '605', '169260', '29', '124400', '573', '426231', '418518', '195']\n",
    "\n",
    "def second_get_details(username, password, test_id_list):\n",
    "    second_details_df = pd.DataFrame()\n",
    "    for ids in second_test_id_list:\n",
    "        second = requests.get('https://api.ravelry.com/patterns.json?ids=' +\n",
    "                     ids, auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        second_result = json.loads(second.content)\n",
    "        detail_df = pd.DataFrame(second_result['patterns']).T\n",
    "        second_details_df = second_details_df.append(detail_df)\n",
    "        print(second_details_df.shape)\n",
    "    return second_details_df.reset_index().rename(columns = {'index': 'patt_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_test_df = second_get_details(username, password, second_test_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: divide list of pattern ids into chunks of 200, resulting in 150 lists within the larger list\n",
    "\n",
    "# How many elements each list should have  \n",
    "n = 200\n",
    "   \n",
    "# using list comprehension  \n",
    "pattid_chunk_list = [pattid_flat_list[i:i + n] for i in range(0, len(pattid_flat_list), n)]  \n",
    "len(pattid_chunk_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to retrieve details for full list of ids, 200 at a time. Try/except added due to a json error in the list\n",
    "# at index 9\n",
    "\n",
    "def get_details(username, password, id_list):\n",
    "    details_df = pd.DataFrame()\n",
    "    for ids in pattid_chunk_list:\n",
    "        res = requests.get('https://api.ravelry.com/patterns.json?ids=' +\n",
    "                           '+'.join(ids), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        try:        \n",
    "            result = json.loads(res.content)\n",
    "            detail_df = pd.DataFrame(result['patterns']).T\n",
    "            details_df = details_df.append(detail_df)\n",
    "            print(details_df.shape)\n",
    "        except:\n",
    "            print(res.content)\n",
    "            continue\n",
    "    return details_df.reset_index().rename(columns = {'index': 'patt_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patt_details_df = get_details(username, password, pattid_chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with the bad value in the chunk at index 9\n",
    "# append the result to patt_details_df to get the complete dataset\n",
    "# code from second step of testing; using index number of problem chunk, pass that in for loop to run on each id\n",
    "# individually\n",
    "# incorporate try/except from previous function to skip over the problem row\n",
    "\n",
    "def get_problem_details(username, password, id_list):\n",
    "    problem_df = pd.DataFrame()\n",
    "    for ids in id_list:\n",
    "        res = requests.get('https://api.ravelry.com/patterns.json?ids=' +\n",
    "                           ids, auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        try:\n",
    "            result = json.loads(res.content)\n",
    "            detail_df = pd.DataFrame(result['patterns']).T\n",
    "            problem_df = problem_df.append(detail_df)\n",
    "            print(problem_df.shape)\n",
    "        except:\n",
    "            print(res.content)\n",
    "            continue\n",
    "    return problem_df.reset_index().rename(columns = {'index': 'patt_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_json_df = get_problem_details(username, password, pattid_chunk_list[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify 'bad' id (I could see where it was from the print statement in the loop)\n",
    "\n",
    "problem = pattid_chunk_list[9]\n",
    "problem[147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repurposing code from first test to see if the problem id can be pulled individually\n",
    "# confirmed that this is definitely the problem id and it cannot be called through API\n",
    "\n",
    "prob_id = requests.get('https://api.ravelry.com/patterns.json?ids=' +\n",
    "                     str(20), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "prob_id_result = json.loads(prob_id.content)\n",
    "prob_id_detail_df = pd.DataFrame(prob_id_result['patterns']).T\n",
    "prob_id_detail_df = prob_id_detail_df.reset_index().rename(columns = {'index': 'patt_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append bad_json_df to patt_details_df for complete pattern details dataset\n",
    "\n",
    "patt_details_df = patt_details_df.append(bad_json_df).reset_index()\n",
    "patt_details_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patt_details_df.to_csv('../data/df_pattdetails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data on yarns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what yarn information looks like\n",
    "\n",
    "def get_yarn_info(username, password):\n",
    "    res = requests.get('https://api.ravelry.com/yarns/search.json?sort=projects&page_size=1000&page=20',\n",
    "                       auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_yarn_info(username, password)\n",
    "result = json.loads(res.content)\n",
    "result['yarns']\n",
    "yarns_df = pd.DataFrame(result['yarns'])\n",
    "yarns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most used yarn has 270.3k projects. 1000th yarn has 2525 projects.\n",
    "\n",
    "2000th has 1277. 3000th - 825. 5000th - 428. 10000th - 189.\n",
    "\n",
    "I think 10000 is enough to be a good number of popular yarns; cutting off at 200 projects is reasonable and limits the data to yarn that can be reasonably expected to be produced professionally.\n",
    "\n",
    "Unlike with the pattern listings, I'm going to get all the yarn data as I can use more than the ID. If the information I can use is duplicated in the yarn details then I won't save the dataframe to a csv.\n",
    "\n",
    "Plan: use function and for loop to get first 10 pages of yarn listings and save into dataframe. Then split id column out into a list and use it to get yarn details, similar to pattern details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get yarn info and put into dataframe\n",
    "\n",
    "def get_yarn_info(username, password):\n",
    "    yarninfo_df = pd.DataFrame()\n",
    "    for page in range(1, 11):\n",
    "        print(page)\n",
    "        res = requests.get('https://api.ravelry.com/yarns/search.json?sort=projects&page_size=1000&page=' + str(page),\n",
    "                           auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        result = json.loads(res.content)\n",
    "        yarns_df = pd.DataFrame(result['yarns'])\n",
    "        print(yarns_df.shape)\n",
    "        yarninfo_df = yarninfo_df.append(yarns_df)\n",
    "        print(yarninfo_df.shape)\n",
    "    return yarninfo_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarnlistings_df = get_yarn_info(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out id column as list\n",
    "\n",
    "yarnid_list = yarnlistings_df.id.to_list()\n",
    "yarnid_list = [str(i) for i in yarnid_list]\n",
    "yarnid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, test one id to determine shape of results\n",
    "# same shape as pattern details (details for an id in a column rather than a row) so use transform as with patterns\n",
    "\n",
    "firstyarn = requests.get('https://api.ravelry.com/yarns.json?ids=' +\n",
    "                     str(2059), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "firstyarn_result = json.loads(firstyarn.content)\n",
    "firstyarn_detail_df = pd.DataFrame(firstyarn_result['yarns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break yarnid_list into chunks of 200\n",
    "\n",
    "# How many elements each list should have  \n",
    "n = 200\n",
    "   \n",
    "# using list comprehension  \n",
    "yarnid_chunk_list = [yarnid_list[i:i + n] for i in range(0, len(yarnid_list), n)]  \n",
    "len(yarnid_chunk_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull yarn details in chunks as with patterns\n",
    "\n",
    "def get_details(username, password, id_list):\n",
    "    details_df = pd.DataFrame()\n",
    "    for ids in yarnid_chunk_list:\n",
    "        res = requests.get('https://api.ravelry.com/yarns.json?ids=' +\n",
    "                           '+'.join(ids), auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        try:        \n",
    "            result = json.loads(res.content)\n",
    "            detail_df = pd.DataFrame(result['yarns']).T\n",
    "            details_df = details_df.append(detail_df)\n",
    "            print(details_df.shape)\n",
    "        except:\n",
    "            print(res.content)\n",
    "            continue\n",
    "    return details_df.reset_index().rename(columns = {'index': 'yarn_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarndetails_df = get_details(username, password, yarnid_chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both yarn dataframes to csvs - will combine in cleaning stage\n",
    "yarndetails_df.to_csv('../data/df_yarndetails.csv')\n",
    "yarnlistings_df.to_csv('../data/df_yarnlistings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data on yarn shops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what shop information looks like\n",
    "\n",
    "def get_shop_info(username, password):\n",
    "    res = requests.get('https://api.ravelry.com/shops/search.json?lat=36.142642&lng=-86.780897&radius=250&units=miles&shop_type_id=1&page_size=1000&page=1',\n",
    "                       auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_shop_info(username, password)\n",
    "result = json.loads(res.content)\n",
    "result['shops']\n",
    "shops_df = pd.DataFrame(result['shops'])\n",
    "shops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shop_info(username, password):\n",
    "    res = requests.get('https://api.ravelry.com/shops/search.json?query=\"Tennessee\"&page_size=1000&shop_type_id=1',\n",
    "                       auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_shop_info(username, password)\n",
    "result = json.loads(res.content)\n",
    "result['shops']\n",
    "shops_df = pd.DataFrame(result['shops'])\n",
    "shops_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geographic search has radius limit of 250 miles which would make it awkward to retrieve listings, but I can pass in state names as a query search and get results. Best strategy is to use list of state names and run a loop. Tried using \"United States\" as query but got back 413 results which doesn't match results using the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = ['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas', 'California', 'Colorado',\n",
    "              'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii',\n",
    "              'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
    "              'Massachusetts', 'Michigan', 'Minnesota', 'Minor Outlying Islands', 'Mississippi', 'Missouri',\n",
    "              'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
    "              'North Carolina', 'North Dakota', 'Northern Mariana Islands', 'Ohio', 'Oklahoma', 'Oregon',\n",
    "              'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
    "              'Texas', 'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia',\n",
    "              'Wisconsin', 'Wyoming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shop info and put into dataframe\n",
    "\n",
    "def get_shop_info(username, password):\n",
    "    shopinfo_df = pd.DataFrame()\n",
    "    for state in state_list:\n",
    "        print(state)\n",
    "        res = requests.get('https://api.ravelry.com/shops/search.json?query=' + state + '&page_size=1000&shop_type_id=1',\n",
    "                           auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        result = json.loads(res.content)\n",
    "        shops_df = pd.DataFrame(result['shops'])\n",
    "        print(shops_df.shape)\n",
    "        shopinfo_df = shopinfo_df.append(shops_df)\n",
    "        print(shopinfo_df.shape)\n",
    "    return shopinfo_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoplisting_df = get_shop_info(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoplisting_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shoplisting_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shop ids into a list\n",
    "\n",
    "shopid_list = shoplisting_df.id.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, test one id to determine shape of results\n",
    "# is in row format instead of a single column, but returns 2 rows for a single shop.\n",
    "# The rows seem to be identical except the row labeled 'id' has a code for country and state, and the one\n",
    "# labeled 'name' has the country and state name.\n",
    "\n",
    "firstshop = requests.get('https://api.ravelry.com/shops/' + str(6459) + '.json', \n",
    "                         auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "firstshop_result = json.loads(firstshop.content)\n",
    "firstshop_detail_df = pd.DataFrame(firstshop_result['shop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstshop_detail_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can only put one shop id in at a time, so use list as is without chunking it\n",
    "\n",
    "def get_shop_details(username, password, id_list):\n",
    "    details_df = pd.DataFrame()\n",
    "    for ids in id_list:\n",
    "        res = requests.get('https://api.ravelry.com/shops/' + str(ids) + '.json', \n",
    "                           auth=requests.auth.HTTPBasicAuth(username, password))\n",
    "        result = json.loads(res.content)\n",
    "        detail_df = pd.DataFrame(result['shop'])\n",
    "        details_df = details_df.append(detail_df)\n",
    "        print(details_df.shape)\n",
    "    return details_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shopdetails_df = get_shop_details(username, password, shopid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save both shop dataframes to csvs - will combine in cleaning stage\n",
    "shopdetails_df.to_csv('../data/df_shopdetails.csv')\n",
    "shoplisting_df.to_csv('../data/df_shoplistings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
