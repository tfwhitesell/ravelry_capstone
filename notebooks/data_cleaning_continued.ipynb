{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More data cleaning\n",
    "\n",
    "The Ravelry data has columns where each row value is a dictionary. To make things simpler, I'd rather break that information up before analysis than try to analyze while dealing with the dictionary structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patterns_df = pd.read_csv('../data/df_patterns_clean.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 60)\n",
    "patterns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern df cleaning to do:\n",
    "- created_at : truncate to year/month/day, possibly convert format\n",
    "- standardize yarn_weight_description (perhaps group thread and cobweb, aran/worsted into one or the other, dk/sport the same - look at pattern guauge to determine which way to go)\n",
    "- packs : break out called-for yarn\n",
    "- craft : break out craft name to new column\n",
    "- pattern_type : break out clothing(T/F) and type name (Socks, Shawl/Wrap etc)\n",
    "\n",
    "\n",
    "Wait on:\n",
    "- pattern_needle_sizes : see if I need this info for analysis\n",
    "- yarn_weight : might not need at all\n",
    "- pattern_categories : might not need since pattern_type contains top-level category\n",
    "- pattern_attributes : if I get extraordinarily ambitious, don't think I'm going to have time to get this far in the weeds\n",
    "\n",
    "Thoughts on dealing with the dictionary columns:\n",
    "\n",
    "As an example, the called-for yarn in the pattern details df is a key/value in a larger dictionary column. I want to extract the yarn name on its own into a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df = patterns_df.rename(columns = {'name' : 'patt_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df.pattern_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df.craft.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split faux-dictionary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split craft column\n",
    "\n",
    "patterns_df['craft'] = patterns_df['craft'].apply(lambda x : dict(eval(x)))\n",
    "temp = patterns_df['craft'].apply(pd.Series)\n",
    "patterns_df = pd.concat([patterns_df, temp], axis = 1).drop('craft', axis = 1)\n",
    "patterns_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df = patterns_df.drop(['id', 'permalink'], 1)\n",
    "patterns_df = patterns_df.rename(columns = {'name' : 'craft_name'})\n",
    "patterns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patterns_df.pattern_type.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried same code on other problem columns, but getting errors even with other approaches\n",
    "# new approach - they're strings, so use split and then trim extra characters\n",
    "\n",
    "pattern_type_df = patterns_df.pattern_type.str.split(\", \", expand = True)\n",
    "pattern_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns I want to keep\n",
    "pattern_type_df = pattern_type_df.rename(columns = {0 : 'clothing', 2 : 'type_name'})\n",
    "\n",
    "# remove label part of clothing column\n",
    "pattern_type_df['clothing'] = pattern_type_df['clothing'].str.replace(r\"{'clothing': \", '')\n",
    "\n",
    "# remove label part of type_name column\n",
    "pattern_type_df['type_name'] = pattern_type_df['type_name'].str.replace(r\"'name': '\", '')\n",
    "\n",
    "# slice off trailing character in type_name column\n",
    "pattern_type_df['type_name'] = pattern_type_df['type_name'].str.slice(0, -1)\n",
    "\n",
    "# drop extra columns\n",
    "pattern_type_df = pattern_type_df.drop([1, 3], 1)\n",
    "pattern_type_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result as expected\n",
    "pattern_type_df.clothing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result as expected\n",
    "pattern_type_df.type_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back to patterns_df on index\n",
    "patterns_df = patterns_df.merge(pattern_type_df, how = 'outer', left_index = True, right_index = True)\n",
    "patterns_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original column\n",
    "patterns_df = patterns_df.drop(['pattern_type'], 1)\n",
    "patterns_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat process for packs column\n",
    "packs_df = patterns_df.packs.str.split(\", \", expand = True)\n",
    "packs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(packs_df[10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns I want to keep\n",
    "packs_df = packs_df.rename(columns = {10 : 'patt_yarn', 16 : 'patt_yarn_weight'})\n",
    "\n",
    "# remove label part of patt_yarn column\n",
    "packs_df['patt_yarn'] = packs_df['patt_yarn'].str.replace(r\"'yarn_name': '\", '')\n",
    "\n",
    "# remove label part of patt_yarn_weight column\n",
    "packs_df['patt_yarn_weight'] = packs_df['patt_yarn_weight'].str.replace(r\"'name': '\", '')\n",
    "\n",
    "# slice off trailing characters in patt_yarn and Patt_yarn_weight columns\n",
    "packs_df['patt_yarn'] = packs_df['patt_yarn'].str.slice(0, -1)\n",
    "packs_df['patt_yarn_weight'] = packs_df['patt_yarn_weight'].str.slice(0, -1)\n",
    "\n",
    "# drop extra columns\n",
    "packs_df = packs_df.drop(packs_df.iloc[:, 0:10], axis = 1)\n",
    "packs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extra columns part 2\n",
    "\n",
    "packs_df = packs_df.drop(packs_df.iloc[:, 1:6], axis = 1)\n",
    "packs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dropping of extra columns\n",
    "\n",
    "packs_df = packs_df.drop(packs_df.iloc[:, 2:], axis = 1)\n",
    "packs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back to patterns_df on index\n",
    "patterns_df = patterns_df.merge(packs_df, how = 'outer', left_index = True, right_index = True)\n",
    "\n",
    "# drop original column\n",
    "patterns_df = patterns_df.drop(['packs'], 1)\n",
    "patterns_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other cleaning on patterns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate created_at column\n",
    "patterns_df['created_at'] = patterns_df['created_at'].str.slice(0, 11)\n",
    "patterns_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns_df.to_csv('../data/df_patterns_clean2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shop data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df = pd.read_csv('../data/df_shop_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice off extraneous info from country and state columns\n",
    "\n",
    "shops_df['country'] = shops_df['country'].str.replace(r\"{'id': 229, 'name': '\", '')\n",
    "shops_df['country'] = shops_df['country'].str.slice(0, -2)\n",
    "shops_df['state'] = shops_df['state'].str.slice(22, -2)\n",
    "\n",
    "shops_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shops with no zip or lat/long\n",
    "\n",
    "noloc_df = shops_df[(shops_df['latitude'].isna()) &\n",
    "                    (shops_df['longitude'].isna())]\n",
    "\n",
    "noloc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noloc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df = shops_df[~shops_df['latitude'].isna() & ~shops_df['longitude'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shops_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df = shops_df.drop_duplicates(['latitude', 'longitude'])\n",
    "shops_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df = shops_df.reset_index(drop = True)\n",
    "shops_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shops_df.to_csv('../data/df_shops_clean2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yarn data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df = pd.read_csv('../data/df_yarn_clean.csv')\n",
    "yarns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning needed:\n",
    "- texture : clean up categories (multiple versions of plied etc)\n",
    "- break out yarn_weight, also drop the extra one that made it through the previous step\n",
    "- break out yarn_fibers\n",
    "\n",
    "save for if needed:\n",
    "- break out min and max needle size, keep metric\n",
    "- break out min and max hook size, keep metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df = yarns_df.rename(columns = {'name' : 'yarn_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df.texture.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim white space\n",
    "yarns_df['texture'] = yarns_df['texture'].str.strip()\n",
    "yarns_df.texture.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easier to do the rest of this step in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split faux-dictionary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yarn_weight\n",
    "yarn_weight_df = yarns_df.yarn_weight_x.str.split(\", \", expand = True)\n",
    "yarn_weight_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns I want to keep\n",
    "yarn_weight_df = yarn_weight_df.rename(columns = {5 : 'yarn_weight', 7 : 'wpi'})\n",
    "\n",
    "# remove label part of columns\n",
    "yarn_weight_df['yarn_weight'] = yarn_weight_df['yarn_weight'].str.replace(r\"'name': '\", '')\n",
    "yarn_weight_df['wpi'] = yarn_weight_df['wpi'].str.replace(r\"'wpi': '\", '')\n",
    "\n",
    "# slice off trailing character in columns\n",
    "yarn_weight_df['yarn_weight'] = yarn_weight_df['yarn_weight'].str.slice(0, -1)\n",
    "yarn_weight_df['wpi'] = yarn_weight_df['wpi'].str.slice(0, -2)\n",
    "\n",
    "# drop extra columns\n",
    "yarn_weight_df = yarn_weight_df.drop([0, 1, 2, 3, 4, 6], 1)\n",
    "yarn_weight_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge back to yarns_df on index\n",
    "yarns_df = yarns_df.merge(yarn_weight_df, how = 'outer', left_index = True, right_index = True)\n",
    "yarns_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original columns\n",
    "yarns_df = yarns_df.drop(['yarn_weight_x', 'yarn_weight_y'], 1)\n",
    "yarns_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yarn_fibers\n",
    "yarn_fibers_df = yarns_df.yarn_fibers.str.split(\", \", expand = True)\n",
    "yarn_fibers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to info on top 3 fibers per yarn\n",
    "yarn_fibers_df[39].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extra columns from the end\n",
    "yarn_fibers_df = yarn_fibers_df.drop(yarn_fibers_df.iloc[:, 39:], axis = 1)\n",
    "yarn_fibers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarn_fibers_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarn_fibers_df[21].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting info out of yarn_fibers isn't going to work without turning it into a real dictionary first. (Each fiber in a yarn can have up to 13 attributes, but not all have the same number so just spliting into columns to deal with it won't work.) Tried code that worked for the craft column in patterns_df but getting same error as before with other columns.\n",
    "\n",
    "yarns_df['yarn_fibers'] = yarns_df['yarn_fibers'].apply(lambda x : dict(eval(x)))\n",
    "temp = yarns_df['yarn_fibers'].apply(pd.Series)\n",
    "yarns_df = pd.concat([yarns_df, temp], axis = 1).drop('yarn_fibers', axis = 1)\n",
    "yarns_df.head()\n",
    "\n",
    "Found this solution of stackoverflow (https://stackoverflow.com/questions/38231591/splitting-dictionary-list-inside-a-pandas-column-into-separate-columns), but it hasn't worked either.\n",
    "\n",
    "yarn_fiber_df = pd.json_normalize(yarns_df['yarn_fibers'])\n",
    "\n",
    "I think json_normalize might work if the column was already a true dictionary (nope), but that's the step at which every approach goes wrong.\n",
    "\n",
    "Tried turning dictionary into a dataframe, but the arrays are different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df['yarn_fibers'].loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast.literal_eval(yarns_df['yarn_fibers'].loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ast.literal_eval(yarns_df['yarn_fibers'].loc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thought this might work, but it doesn't do quite what I want\n",
    "\n",
    "#yarns_df['yarn_fibers'] = yarns_df['yarn_fibers'].apply(lambda x : ast.literal_eval(x))\n",
    "#temp = yarns_df['yarn_fibers'].apply(pd.Series)\n",
    "#yarns_df = pd.concat([yarns_df, temp], axis = 1)#.drop('yarn_fibers', axis = 1)\n",
    "#yarns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df['yarn_fibers'].apply(lambda x : len(ast.literal_eval(x))).value_counts()\n",
    "# if I understand correctly, this result indicates how many fibers are listed for each yarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarn_dict = yarns_df['yarn_fibers'].apply(lambda x : ast.literal_eval(x)[0] if len(ast.literal_eval(x)) > 0 else {})\n",
    "# properly turns column into a dictionary\n",
    "# does it only pull the first fiber? I think so. How to change this to pull each yarn firber component in turn?\n",
    "# I think this is what Mahesh was talking about when he recommended a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarnfiber_df = yarn_dict.apply(pd.Series)\n",
    "# takes each dictionary element and puts it in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarnfiber_df\n",
    "# fiber_type and fiber_category are both dictionaries so they need further steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply_test2 = temp['fiber_type'].apply(lambda x : ast.literal_eval(x) if len(ast.literal_eval(x)) > 0 else {})\n",
    "yarnfiber_type_df = yarnfiber_df['fiber_type'].apply(pd.Series)\n",
    "yarnfiber_type_df\n",
    "# repeat .apply to breakout formerly nested dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahesh recommends a function to accomplish turning problem columns into dictionaries and then breaking them into constituent parts. Also, use the function in place of lambda.\n",
    "\n",
    "What are the steps?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarnfiber_category_df = yarnfiber_df['fiber_category'].apply(pd.Series)\n",
    "yarnfiber_category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarnfiber_parent_df = yarnfiber_category_df['parent'].apply(pd.Series)\n",
    "yarnfiber_parent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to take the first fiber listed for purpose of immediate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge percentage from yarnfiber_df\n",
    "yarns_df = yarns_df.join(yarnfiber_df, rsuffix='_y')\n",
    "yarns_df = yarns_df.drop(['id', 'fiber_type', 'fiber_category'], axis = 1)\n",
    "yarns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge fiber info from yarnfiber_type_df\n",
    "yarns_df = yarns_df.join(yarnfiber_type_df)\n",
    "yarns_df = yarns_df.drop([0, 'id'], axis = 1)\n",
    "yarns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df = yarns_df.drop([0, 'id'], axis = 1)\n",
    "yarns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge fiber category info from yarnfiber_category_df\n",
    "yarns_df = yarns_df.join(yarnfiber_category_df, rsuffix='_y')\n",
    "yarns_df = yarns_df.drop([0, 'id', 'parent', 'permalink'], axis = 1)\n",
    "yarns_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yarns_df = yarns_df.rename(columns = {'name_y' : 'fiber_catt_name'})\n",
    "yarns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned yarn dataframe to csv\n",
    "\n",
    "yarns_df.to_csv('../data/df_yarn_clean2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
